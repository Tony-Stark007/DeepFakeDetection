{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5lzELo8SDnt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AqHVFrb9SDnx"
      },
      "outputs": [],
      "source": [
        "path = '../ColabNotebooks/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ucq8OBXqSDny"
      },
      "outputs": [],
      "source": [
        "def extractFrames(file_name, frame_step):\n",
        "  video = imageio.get_reader(file_name, 'ffmpeg')\n",
        "  return np.array([frame for i, frame in enumerate(video) if i % frame_step == 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GR0i5FQySDny"
      },
      "outputs": [],
      "source": [
        "def preProcessing(frames):\n",
        "  video_r_channel = np.zeros(frames.shape[0:3])\n",
        "  video_g_channel = np.zeros(frames.shape[0:3])\n",
        "  video_b_channel = np.zeros(frames.shape[0:3])\n",
        "\n",
        "  for i, frame in enumerate(frames):\n",
        "    for j, row in enumerate(frame):\n",
        "      for k, pixel in enumerate(row):\n",
        "        video_r_channel[i][j][k] = pixel[0]\n",
        "        video_g_channel[i][j][k] = pixel[1]\n",
        "        video_b_channel[i][j][k] = pixel[2]\n",
        "        \n",
        "  return video_r_channel, video_g_channel, video_b_channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MmGAf8iiSDnz"
      },
      "outputs": [],
      "source": [
        "# Returns correlation value\n",
        "def superimpose(frame: np.ndarray, kernel: np.ndarray):\n",
        "  n = kernel.shape[0]\n",
        "  mid = n // 2\n",
        "\n",
        "  superimposed_matrix = frame * kernel\n",
        "  return sum(superimposed_matrix.flatten()) - superimposed_matrix[mid][mid]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SXThZJUlSDnz"
      },
      "outputs": [],
      "source": [
        "def isValid(index, length, skip):\n",
        "  return index >= skip and index < length - skip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ctFjbbRsSDn0"
      },
      "outputs": [],
      "source": [
        "# Channel is a 3D matrix: (number of frames, height, width)\n",
        "# each element represents the pixel value of the given channel\n",
        "\n",
        "def convolve(channel, kernel):\n",
        "  n = len(kernel) # Kernel is of dimension n x n\n",
        "  skip = n // 2 # No. of rows and cols to be skipped\n",
        "\n",
        "  num_frames, height, width = channel.shape\n",
        "\n",
        "  # res_frames = np.zeros((len(frames), height - 2 * skip, width - 2 * skip))\n",
        "  res_channel = np.zeros(channel.shape)\n",
        "\n",
        "  for i, frame in enumerate(channel):\n",
        "    print(f'Frame: {i}')\n",
        "\n",
        "    for j, row in enumerate(frame):\n",
        "      if not isValid(j, height, skip):\n",
        "        continue\n",
        "\n",
        "      for k, pixel in enumerate(row):\n",
        "        if not isValid(k, width, skip):\n",
        "          continue\n",
        "\n",
        "        subframe = frame[j - skip: j + skip + 1, k - skip: k + skip + 1]\n",
        "\n",
        "        res_channel[i][j][k] = superimpose(subframe, kernel)\n",
        "\n",
        "  return res_channel[:, skip:-skip, skip:-skip]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8gr8TtQzSDn1"
      },
      "outputs": [],
      "source": [
        "def saveAsVideo(frames, file_name, fps):\n",
        "  frames = frames.astype('uint8')\n",
        "  writer = imageio.get_writer(file_name, fps=fps, macro_block_size=None)\n",
        "  for frame in frames:\n",
        "    writer.append_data(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_training_data(frame, kernel_size):\n",
        "  skip = kernel_size // 2 # No. of rows and cols to be skipped\n",
        "\n",
        "  height, width = frame.shape\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for i, row in enumerate(frame):\n",
        "    if not isValid(i, height, skip):\n",
        "      continue\n",
        "\n",
        "    for j, pixel in enumerate(row):\n",
        "      if not isValid(j, width, skip):\n",
        "        continue\n",
        "\n",
        "      subframe = frame[i - skip: i + skip + 1, j - skip: j + skip + 1]\n",
        "\n",
        "      X.append(np.delete(subframe.flatten(), skip * kernel_size + skip))\n",
        "      Y.append(subframe[skip, skip])\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "CgpITjhYSDn1"
      },
      "outputs": [],
      "source": [
        "#driver code\n",
        "files = os.listdir(path)\n",
        "\n",
        "frames = np.array(extractFrames(os.path.join(path, files[5]), 30))\n",
        "video_r_channel, video_g_channel, video_b_channel = preProcessing(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb1w1NLiSDn3",
        "outputId": "6628c6e9-e5ef-45b5-cfbc-a39961210e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[163., 163., 163., ..., 158., 158., 158.],\n",
              "       [163., 163., 163., ..., 158., 158., 158.],\n",
              "       [163., 163., 163., ..., 159., 159., 159.],\n",
              "       ...,\n",
              "       [ 52.,  51.,  51., ..., 253., 253., 253.],\n",
              "       [ 52.,  52.,  52., ..., 253., 253., 253.],\n",
              "       [ 52.,  52.,  52., ..., 253., 253., 253.]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actual = video_r_channel[0][1:-1, 1:-1]\n",
        "actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, Y = get_training_data(video_b_channel[0], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('sgdregressor', SGDRegressor())])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l_model = make_pipeline(StandardScaler(), SGDRegressor())\n",
        "l_model.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9983248651893777"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l_model.score(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-17.03503111  32.33820182 -15.58306979  33.81088394  33.71901943\n",
            " -15.63631079  32.35098649 -17.04748517]\n",
            "[79.22787353]\n"
          ]
        }
      ],
      "source": [
        "print(l_model['sgdregressor'].coef_)\n",
        "print(l_model['sgdregressor'].intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_frame = l_model.predict(X).reshape(actual.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "err_frame = abs(pred_frame - actual).astype('uint8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "imageio.imwrite('org_gradient_descent_error_b.jpg', err_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.24688925665398725"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(abs(actual.flatten() - l_model.predict(X))) / len(actual.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJyVVU2MSDn2"
      },
      "outputs": [],
      "source": [
        "saveAsVideo(video_r_channel, 'video_r.mp4', 5)\n",
        "saveAsVideo(video_g_channel, 'video_g.mp4', 5)\n",
        "saveAsVideo(video_b_channel, 'video_b.mp4', 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpq_TXdeSDn3",
        "outputId": "a017f58a-8560-4cfc-c32d-eaf70ce6d09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame: 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[144, 144, 144, ..., 140, 140, 140],\n",
              "        [144, 144, 144, ..., 140, 140, 140],\n",
              "        [144, 144, 144, ..., 140, 140, 140],\n",
              "        ...,\n",
              "        [ 45,  45,  45, ..., 224, 224, 224],\n",
              "        [ 46,  46,  45, ..., 224, 224, 224],\n",
              "        [ 47,  46,  46, ..., 224, 224, 224]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predicted = convolve(np.array([video_r_channel[0]]), kernel).astype('uint8')\n",
        "predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibIZf2eBSDn4"
      },
      "outputs": [],
      "source": [
        "imageio.imwrite('predicted_image_r.jpg', predicted[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZKVZLc2SDn4",
        "outputId": "1e8e6d94-b5b7-4475-b331-649e60573e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[19, 19, 19, ..., 18, 18, 18],\n",
              "       [19, 19, 19, ..., 18, 18, 18],\n",
              "       [19, 19, 19, ..., 19, 19, 19],\n",
              "       ...,\n",
              "       [ 7,  6,  6, ..., 29, 29, 29],\n",
              "       [ 6,  6,  7, ..., 29, 29, 29],\n",
              "       [ 5,  6,  6, ..., 29, 29, 29]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "diff = abs(actual - predicted[0]).astype('uint8')\n",
        "diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3hgX7eeSDn4",
        "outputId": "2e843948-fdda-4f07-f065-f45c243dac1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13.366895691824933"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "(1 / len(diff.flatten())) * sum(diff.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa_pYlDHSDn4"
      },
      "outputs": [],
      "source": [
        "imageio.imwrite('error_image_r.jpg', diff)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "DeepFakeDetection.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
